{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b1d9663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sn; sn.set(font_scale = 1.4)\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "675784ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}\n"
     ]
    }
   ],
   "source": [
    "class_names = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
    "class_name_labels = {class_name : i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "number_of_classes = len(class_names)\n",
    "print(class_name_labels)\n",
    "IMAGE_SIZE = (180, 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d0d3924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    DIRECTORY = r\"D:\\College\\Projects\\Flower_Recognition\"\n",
    "    CATEGORY = ['training_set', 'test_set']\n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    for category in CATEGORY:\n",
    "        path = os.path.join(DIRECTORY, category)\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        print('loading {}'.format(category))\n",
    "        \n",
    "        for folder in os.listdir(path):\n",
    "            label = class_name_labels[folder]\n",
    "            \n",
    "            for file in os.listdir(os.path.join(path, folder)):\n",
    "                img_path = os.path.join(os.path.join(path, folder), file)\n",
    "                \n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, IMAGE_SIZE)\n",
    "                \n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "                \n",
    "        images = np.array(images, dtype = 'float32')\n",
    "        labels = np.array(labels, dtype = 'int32')\n",
    "            \n",
    "        output.append((images, labels))\n",
    "        \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a4c1a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training_set\n",
      "loading test_set\n"
     ]
    }
   ],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85abd243",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images, training_labels = shuffle(training_images, training_labels, random_state = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc14268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(180,\n",
    "                                  180,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5012a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "     \n",
    "  data_augmentation,\n",
    "\n",
    "  layers.Rescaling(1./255),\n",
    "  \n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  \n",
    "\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes, name=\"outputs\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0c941ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8343022c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_2 (Sequential)   (None, 180, 180, 3)       0         \n",
      "                                                                 \n",
      " rescaling_1 (Rescaling)     (None, 180, 180, 3)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 180, 180, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 90, 90, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 90, 90, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 45, 45, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 22, 22, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 30976)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               3965056   \n",
      "                                                                 \n",
      " outputs (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,989,285\n",
      "Trainable params: 3,989,285\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38e82c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "23/23 [==============================] - 36s 1s/step - loss: 0.4867 - accuracy: 0.8119 - val_loss: 0.9054 - val_accuracy: 0.6791\n",
      "Epoch 2/22\n",
      "23/23 [==============================] - 33s 1s/step - loss: 0.4440 - accuracy: 0.8377 - val_loss: 0.8653 - val_accuracy: 0.6928\n",
      "Epoch 3/22\n",
      "23/23 [==============================] - 31s 1s/step - loss: 0.4323 - accuracy: 0.8308 - val_loss: 0.8565 - val_accuracy: 0.6804\n",
      "Epoch 4/22\n",
      "23/23 [==============================] - 31s 1s/step - loss: 0.4173 - accuracy: 0.8425 - val_loss: 0.9282 - val_accuracy: 0.6529\n",
      "Epoch 5/22\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.4182 - accuracy: 0.8387 - val_loss: 0.7854 - val_accuracy: 0.7176\n",
      "Epoch 6/22\n",
      "23/23 [==============================] - 33s 1s/step - loss: 0.3699 - accuracy: 0.8615 - val_loss: 0.8977 - val_accuracy: 0.7066\n",
      "Epoch 7/22\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.4048 - accuracy: 0.8522 - val_loss: 0.8377 - val_accuracy: 0.7135\n",
      "Epoch 8/22\n",
      "23/23 [==============================] - 34s 1s/step - loss: 0.3731 - accuracy: 0.8591 - val_loss: 0.8223 - val_accuracy: 0.6970\n",
      "Epoch 9/22\n",
      "23/23 [==============================] - 35s 2s/step - loss: 0.3324 - accuracy: 0.8777 - val_loss: 0.8976 - val_accuracy: 0.7052\n",
      "Epoch 10/22\n",
      "23/23 [==============================] - 33s 1s/step - loss: 0.3175 - accuracy: 0.8849 - val_loss: 0.8715 - val_accuracy: 0.7273\n",
      "Epoch 11/22\n",
      "23/23 [==============================] - 34s 1s/step - loss: 0.2995 - accuracy: 0.8977 - val_loss: 0.8557 - val_accuracy: 0.7245\n",
      "Epoch 12/22\n",
      "23/23 [==============================] - 39s 2s/step - loss: 0.2977 - accuracy: 0.8911 - val_loss: 0.9270 - val_accuracy: 0.7135\n",
      "Epoch 13/22\n",
      "23/23 [==============================] - 38s 2s/step - loss: 0.2682 - accuracy: 0.9063 - val_loss: 0.9893 - val_accuracy: 0.6942\n",
      "Epoch 14/22\n",
      "23/23 [==============================] - 38s 2s/step - loss: 0.2416 - accuracy: 0.9166 - val_loss: 0.9477 - val_accuracy: 0.7163\n",
      "Epoch 15/22\n",
      "23/23 [==============================] - 34s 1s/step - loss: 0.2253 - accuracy: 0.9183 - val_loss: 0.9686 - val_accuracy: 0.7273\n",
      "Epoch 16/22\n",
      "23/23 [==============================] - 36s 2s/step - loss: 0.2215 - accuracy: 0.9280 - val_loss: 1.0495 - val_accuracy: 0.6873\n",
      "Epoch 17/22\n",
      "23/23 [==============================] - 35s 2s/step - loss: 0.2554 - accuracy: 0.9004 - val_loss: 0.9271 - val_accuracy: 0.7369\n",
      "Epoch 18/22\n",
      "23/23 [==============================] - 36s 2s/step - loss: 0.2136 - accuracy: 0.9266 - val_loss: 0.9591 - val_accuracy: 0.7190\n",
      "Epoch 19/22\n",
      "23/23 [==============================] - 38s 2s/step - loss: 0.1898 - accuracy: 0.9404 - val_loss: 0.9843 - val_accuracy: 0.7163\n",
      "Epoch 20/22\n",
      "23/23 [==============================] - 36s 2s/step - loss: 0.1878 - accuracy: 0.9338 - val_loss: 1.0477 - val_accuracy: 0.7080\n",
      "Epoch 21/22\n",
      "23/23 [==============================] - 33s 1s/step - loss: 0.1506 - accuracy: 0.9511 - val_loss: 1.0920 - val_accuracy: 0.7080\n",
      "Epoch 22/22\n",
      "23/23 [==============================] - 34s 1s/step - loss: 0.1778 - accuracy: 0.9418 - val_loss: 1.0392 - val_accuracy: 0.7314\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(training_images, training_labels, batch_size = 128, epochs = 22, validation_split= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4f9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('final_model2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a257295",
   "metadata": {},
   "source": [
    "## Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28d2f056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 162ms/step - loss: 0.9271 - accuracy: 0.6604\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_images, test_labels, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d736e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
